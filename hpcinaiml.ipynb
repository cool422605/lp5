{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import time\n"
      ],
      "metadata": {
        "id": "1FeQAv9VLc6V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the data preprocessing function\n",
        "def preprocess_data(x):\n",
        "    # Perform some data preprocessing operations\n",
        "    x = x.reshape(-1, 784).astype('float32') / 255.0\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "vy6SvjUjMkGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "qNBTYrX0MibB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the number of processes to use\n",
        "num_processes = multiprocessing.cpu_count()\n"
      ],
      "metadata": {
        "id": "-lc274U5Mk1g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a multiprocessing Pool\n",
        "pool = multiprocessing.Pool(processes=num_processes)\n"
      ],
      "metadata": {
        "id": "XdIDdoCyMnNt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the training data into chunks for parallel processing\n",
        "chunk_size = len(x_train) // num_processes\n",
        "train_data_chunks = [x_train[i:i+chunk_size] for i in range(0, len(x_train), chunk_size)]\n"
      ],
      "metadata": {
        "id": "y4IMI4uzMpO4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Start time for data preprocessing\n",
        "start_time = time.time()\n"
      ],
      "metadata": {
        "id": "wV6NgKI8MqtN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply the data preprocessing function in parallel for training data\n",
        "preprocessed_train_data = np.concatenate(pool.map(preprocess_data, train_data_chunks))\n"
      ],
      "metadata": {
        "id": "i5RT-fK3MrVL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# End time for data preprocessing\n",
        "end_time = time.time()\n",
        "preprocessing_time = end_time - start_time\n"
      ],
      "metadata": {
        "id": "Z4oumzidMr4s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the test data into chunks for parallel processing\n",
        "chunk_size = len(x_test) // num_processes\n",
        "test_data_chunks = [x_test[i:i+chunk_size] for i in range(0, len(x_test), chunk_size)]\n"
      ],
      "metadata": {
        "id": "x-pVaH9zMsZq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Start time for data preprocessing of test data\n",
        "start_time = time.time()\n"
      ],
      "metadata": {
        "id": "LhZ0TuAGMs-s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply the data preprocessing function in parallel for test data\n",
        "preprocessed_test_data = np.concatenate(pool.map(preprocess_data, test_data_chunks))\n"
      ],
      "metadata": {
        "id": "5yS_S8TlMtlP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# End time for data preprocessing of test data\n",
        "end_time = time.time()\n",
        "preprocessing_time += end_time - start_time\n"
      ],
      "metadata": {
        "id": "QJUHCqswMuDh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Close the multiprocessing Pool\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "print(f\"Time taken for data preprocessing: {preprocessing_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clp-fOisMu3i",
        "outputId": "143c67f6-f39e-4609-8bbe-feb153906699"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for data preprocessing: 11.64 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use the preprocessed data in your DL task\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "duDsaukSMv43"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Start time for model training\n",
        "start_time = time.time()\n"
      ],
      "metadata": {
        "id": "fp6WaqVJMxT2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model with the preprocessed data\n",
        "model.fit(preprocessed_train_data, y_train, epochs=10, batch_size=32, validation_data=(preprocessed_test_data, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K_pBXRSMzHW",
        "outputId": "200df7a0-43c0-47b2-f34d-90d334889c43"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2703 - accuracy: 0.9212 - val_loss: 0.1494 - val_accuracy: 0.9550\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1234 - accuracy: 0.9630 - val_loss: 0.1075 - val_accuracy: 0.9687\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0908 - accuracy: 0.9719 - val_loss: 0.1004 - val_accuracy: 0.9697\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0724 - accuracy: 0.9774 - val_loss: 0.1051 - val_accuracy: 0.9663\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.0879 - val_accuracy: 0.9757\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0423 - accuracy: 0.9864 - val_loss: 0.1073 - val_accuracy: 0.9703\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0969 - val_accuracy: 0.9727\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0932 - val_accuracy: 0.9742\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0936 - val_accuracy: 0.9733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e3cb10940>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# End time for model training\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(f\"Time taken for model training: {training_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "FN2FpzOKMzkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the trained model\n",
        "start_time = time.time()\n",
        "_, accuracy = model.evaluate(preprocessed_test_data, y_test)\n",
        "end_time = time.time()\n",
        "evaluation_time = end_time - start_time\n",
        "\n",
        "print(f\"Time taken for model evaluation: {evaluation_time:.2f} seconds\")\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaUL0olCM0gk",
        "outputId": "0708a2d1-f9ca-4db3-cc9d-1b175690d9ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1043 - accuracy: 0.9727\n",
            "Time taken for model evaluation: 0.87 seconds\n",
            "Accuracy: 0.9726999998092651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6erYwBmBMH79"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}